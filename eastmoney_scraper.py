# -*- coding: utf-8 -*-
"""
Eastmoney Financial Data Scraper (Revised)

This script scrapes daily A-share market data from eastmoney.com.
It provides two main functions:
1. scrape_midday_data(): For scraping data after the morn# ==============================================================================
# 3. ä»»åŠ¡è°ƒåº¦ä¸è¾“å‡º (Task Orchestration & Output)
# ==============================================================================

def save_to_json_file(data: dict, data_type: str) -> str:ession closes.
2. scrape_eod_data(): For scraping complete data after the market closes for the day.

Author: AI Python Development Expert
Date: 2025-08-14
Revision: 1.2 - Upgraded APIs for market sentiment and sector rankings for stability. Fixed index codes.
"""

import requests
import json
import time
import random
import os
from datetime import datetime
import argparse

# ==============================================================================
# 1. é…ç½®æ¨¡å— (Configuration Module)
# ==============================================================================

CONFIG = {
    'headers': {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',
        'Accept': '*/*',
        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
        'Referer': 'http://data.eastmoney.com/',
        'Connection': 'keep-alive',
    },
    'api': {
        # å¤§ç›˜æ ¸å¿ƒæŒ‡æ•°
        'market_indices': 'http://push2.eastmoney.com/api/qt/ulist.np/get',
        # ã€æ–°ã€‘å¸‚åœºæƒ…ç»ªæ¦‚è§ˆ (æ¶¨è·Œå®¶æ•°ç­‰)
        'market_sentiment_summary': 'https://datacenter-web.eastmoney.com/api/data/v1/get',
        # åŒ—å‘èµ„é‡‘
        'northbound_flow': 'http://datacenter-web.eastmoney.com/api/data/v1/get',
        # æ¿å—æ’è¡Œ (è¡Œä¸š/æ¦‚å¿µ)
        'sector_ranking': 'http://push2.eastmoney.com/api/qt/clist/get',
        # ä¸ªè‚¡é¾™è™æ¦œ
        'long_hu_bang': 'http://datacenter-web.eastmoney.com/api/data/v1/get',
    },
    'params': {
        'market_indices_fields': "f2,f3,f4,f5,f6,f12,f14,f15,f16,f17,f18",
        # ã€ä¿®æ­£ã€‘æ›´æ–°ç§‘åˆ›50æŒ‡æ•°ä»£ç 
        'market_indices_codes': "1.000001,0.399001,0.399006,1.000688", # ä¸Šè¯, æ·±è¯, åˆ›ä¸š, ç§‘åˆ›50
        # ã€æ–°ã€‘å¸‚åœºæƒ…ç»ªæ¦‚è§ˆæŠ¥å‘Šåç§°
        'market_sentiment_report_name': "RPT_A_STOCK_MARKET_SURVEY",
        'northbound_report_name': "RPT_MUTUAL_DEAL_STA",
        'sector_ranking_fields': "f2,f3,f12,f14,f62,f128,f136,f152",
        'long_hu_bang_report_name': "RPT_DAILYBILLBOARD_DETAILS",
    }
}

# ==============================================================================
# 2. æ ¸å¿ƒæŠ“å–å‡½æ•° (Core Scraping Functions)
# ==============================================================================

def _make_request(url: str, params: dict, method: str = 'GET') -> dict | None:
    """é€šç”¨ç½‘ç»œè¯·æ±‚å‡½æ•°"""
    try:
        time.sleep(random.uniform(1, 2))
        if method.upper() == 'GET':
            response = requests.get(url, headers=CONFIG['headers'], params=params, timeout=10)
        else:
            response = requests.post(url, headers=CONFIG['headers'], data=params, timeout=10)
        response.raise_for_status()
        text = response.text
        if '(' in text and ')' in text:
            text = text[text.find('(') + 1 : text.rfind(')')]
        return json.loads(text)
    except requests.exceptions.RequestException as e:
        print(f"[-] ç½‘ç»œè¯·æ±‚å¤±è´¥: {url}, é”™è¯¯: {e}")
    except json.JSONDecodeError as e:
        print(f"[-] JSONè§£æå¤±è´¥: {url}, å“åº”å†…å®¹: {response.text[:100]}..., é”™è¯¯: {e}")
    except Exception as e:
        print(f"[-] å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
    return None

def get_market_indices() -> list:
    """æŠ“å–å››å¤§æ ¸å¿ƒæŒ‡æ•°æ•°æ®"""
    print("[+] æ­£åœ¨æŠ“å–å¤§ç›˜æ ¸å¿ƒæŒ‡æ•°...")
    params = {
        'pn': '1', 'pz': '10', 'po': '1', 'np': '1',
        'ut': 'bd1d9ddb04089700cf9c27f6f7426281',
        'fltt': '2', 'invt': '2', 'fid': 'f3',
        'secids': CONFIG['params']['market_indices_codes'],
        'fields': CONFIG['params']['market_indices_fields'],
        '_': str(int(time.time() * 1000))
    }
    data = _make_request(CONFIG['api']['market_indices'], params)
    if not data or not data.get('data') or not data['data'].get('diff'):
        print("[-] æœªèƒ½è·å–å¤§ç›˜æŒ‡æ•°æ•°æ®ã€‚")
        return []
    indices_list = []
    for item in data['data']['diff']:
        indices_list.append({
            "name": item.get('f14', '-'),
            "current_point": item.get('f2', 0),
            "change_amount": item.get('f4', 0),
            "change_percent": item.get('f3', 0),
            "turnover_value_cny_billion": round(item.get('f6', 0) / 100000000, 2),
            "turnover_volume_hand": round(item.get('f5', 0) / 100),
            "open_point": item.get('f17', 0),
            "high_point": item.get('f15', 0),
            "low_point": item.get('f16', 0)
        })
    return indices_list

def get_market_sentiment() -> dict:
    """ã€å·²é‡æ„ã€‘æŠ“å–å¸‚åœºæƒ…ç»ªæ•°æ®ï¼ŒåŒ…æ‹¬æ¶¨è·Œå®¶æ•°ã€åŒ—å‘èµ„é‡‘ç­‰"""
    print("[+] æ­£åœ¨æŠ“å–å¸‚åœºæƒ…ç»ªæ¦‚è§ˆ...")
    sentiment_data = {}
    trade_date = datetime.now().strftime('%Y-%m-%d')

    # 1. ã€æ–°APIã€‘è·å–æ¶¨è·Œå®¶æ•°ã€æ¶¨è·Œåœç­‰
    params_summary = {
        'columns': 'ALL',
        'filter': f"(TRADE_DATE='{trade_date}')",
        'reportName': CONFIG['params']['market_sentiment_report_name'],
        'source': 'WEB',
        '_': str(int(time.time() * 1000))
    }
    summary_data = _make_request(CONFIG['api']['market_sentiment_summary'], params_summary)
    if summary_data and summary_data.get('result') and summary_data['result'].get('data'):
        market_info = summary_data['result']['data'][0]
        sentiment_data.update({
            "rising_count": market_info.get('UP_COUNT', 0),
            "falling_count": market_info.get('DOWN_COUNT', 0),
            "flat_count": market_info.get('FLAT_COUNT', 0),
            "limit_up_count": market_info.get('LIMIT_UP_COUNT', 0),
            "limit_down_count": market_info.get('LIMIT_DOWN_COUNT', 0),
            "yesterday_limit_up_performance": f"{market_info.get('ZT_YESTERDAY_PERFORMANCE', 0)}%"
        })
    else:
        print("[-] æœªèƒ½è·å–æ¶¨è·Œå®¶æ•°æ•°æ®ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥ï¼‰ã€‚")

    # 2. è·å–åŒ—å‘èµ„é‡‘
    params_north = {
        'columns': 'ALL',
        'filter': f"(TRADE_DATE='{trade_date}')",
        'pageNumber': '1', 'pageSize': '1',
        'reportName': CONFIG['params']['northbound_report_name'],
        'sortColumns': 'TRADE_DATE', 'sortTypes': '-1',
        'source': 'WEB',
        '_': str(int(time.time() * 1000))
    }
    north_data = _make_request(CONFIG['api']['northbound_flow'], params_north)
    if north_data and north_data.get('result') and north_data['result'].get('data'):
        flow_info = north_data['result']['data'][0]
        sentiment_data["northbound_net_inflow_cny_billion"] = flow_info.get('NET_AMT', 0)
    else:
        print("[!] æœªèƒ½è·å–åŒ—å‘èµ„é‡‘æ•°æ®ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥æˆ–æ•°æ®æœªæ›´æ–°ï¼‰ã€‚")
        sentiment_data["northbound_net_inflow_cny_billion"] = "N/A"

    return sentiment_data

def get_sector_rankings() -> dict:
    """ã€å·²é‡æ„ã€‘æŠ“å–è¡Œä¸šæ¿å—å’Œæ¦‚å¿µæ¿å—æ¶¨å¹…æ¦œTop 10"""
    print("[+] æ­£åœ¨æŠ“å–æ¿å—æ’è¡Œ...")
    rankings = {"industry_top_10": [], "concept_top_10": []}

    def _fetch_top_sectors(board_type: str, fs_param: str) -> list:
        print(f"  - æ­£åœ¨è·å– {board_type} Top 10...")
        params = {
            'pn': '1', 'pz': '10', 'po': '1', 'np': '1',
            'ut': 'bd1d9ddb04089700cf9c27f6f7426281',
            'fltt': '2', 'invt': '2', 'fid': 'f3',
            'fs': fs_param, # ã€ä¿®æ­£ã€‘ä½¿ç”¨ä»å®˜ç½‘åˆ†æå‡ºçš„æœ€æ–°ç¨³å®šå‚æ•°
            'fields': CONFIG['params']['sector_ranking_fields'],
            '_': str(int(time.time() * 1000))
        }
        data = _make_request(CONFIG['api']['sector_ranking'], params)
        sector_list = []
        if not data or not data.get('data') or not data['data'].get('diff'):
            print(f"[-] æœªèƒ½è·å–{board_type}æ¿å—æ•°æ®ã€‚")
            return []
        for item in data['data']['diff']:
            sector_list.append({
                "sector_name": item.get('f14', '-'),
                "change_percent": item.get('f3', 0),
                "leader_stock": {
                    "name": item.get('f128', '-'),
                    "change_percent": item.get('f136', 0)
                }
            })
        return sector_list

    # ã€ä¿®æ­£ã€‘ä½¿ç”¨æœ€æ–°çš„fså‚æ•°
    rankings["industry_top_10"] = _fetch_top_sectors("è¡Œä¸šæ¿å—", "m:90+t:2+f:!50")
    rankings["concept_top_10"] = _fetch_top_sectors("æ¦‚å¿µæ¿å—", "m:90+t:3+f:!50")
    
    return rankings

def get_long_hu_bang() -> list:
    """æŠ“å–ä¸ªè‚¡é¾™è™æ¦œæ•°æ® (ä»…ç›˜å)"""
    print("[+] æ­£åœ¨æŠ“å–ä¸ªè‚¡é¾™è™æ¦œ...")
    params = {
        'columns': 'ALL',
        'filter': "(TRADE_DATE=^" + datetime.now().strftime('%Y-%m-%d') + "^)",
        'pageNumber': '1', 'pageSize': '200',
        'reportName': CONFIG['params']['long_hu_bang_report_name'],
        'sortColumns': 'TOTAL_BUY', 'sortTypes': '-1',
        'source': 'WEB',
        '_': str(int(time.time() * 1000))
    }
    data = _make_request(CONFIG['api']['long_hu_bang'], params)
    if not data or not data.get('result') or not data['result'].get('data'):
        print("[-] æœªèƒ½è·å–é¾™è™æ¦œæ•°æ®ï¼ˆå¯èƒ½æ˜¯éäº¤æ˜“æ—¥æˆ–å½“æ—¥æ— è‚¡ç¥¨ä¸Šæ¦œï¼‰ã€‚")
        return []
    lhb_list = []
    processed_codes = set()
    for item in data['result']['data']:
        stock_code = item.get('SECURITY_CODE')
        if stock_code in processed_codes: continue
        buyers, sellers = [], []
        for i in range(1, 6):
            if item.get(f'OPERATEDEPT_NAME_{i}'):
                buyers.append({"name": item.get(f'OPERATEDEPT_NAME_{i}'), "net_buy_cny_wan": round(item.get(f'BUY_{i}', 0) / 10000, 2)})
            if item.get(f'OPERATEDEPT_NAME_{i+5}'):
                 sellers.append({"name": item.get(f'OPERATEDEPT_NAME_{i+5}'), "net_sell_cny_wan": round(item.get(f'SELL_{i+5}', 0) / 10000, 2)})
        lhb_list.append({
            "stock_code": stock_code, "stock_name": item.get('SECURITY_NAME'),
            "reason": item.get('EXPLANATION'),
            "top_5_buyers": buyers, "top_5_sellers": sellers
        })
        processed_codes.add(stock_code)
    return lhb_list

# ==============================================================================
# 3. ä»»åŠ¡è°ƒåº¦ä¸è¾“å‡º (Task Orchestration & Output)
# ==============================================================================

def _save_to_json_file(data: dict, data_type: str) -> str:
    """
    å°†æ•°æ®ä¿å­˜åˆ°æŒ‰æ—¥æœŸåˆ†ç±»çš„JSONæ–‡ä»¶ä¸­
    
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®å­—å…¸
        data_type: æ•°æ®ç±»å‹ï¼Œ'MIDDAY_DATA' æˆ– 'EOD_DATA'
    
    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    # è·å–å½“å‰æ—¥æœŸ
    current_date = datetime.now()
    date_str = current_date.strftime('%Y-%m-%d')
    
    # åˆ›å»ºæ—¥æœŸæ–‡ä»¶å¤¹
    base_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.join(base_dir, 'data', date_str)
    os.makedirs(data_dir, exist_ok=True)
    
    # ç¡®å®šæ–‡ä»¶å
    time_period = "morning" if data_type == "MIDDAY_DATA" else "afternoon"
    timestamp = current_date.strftime('%H%M%S')
    filename = f"{date_str}_{time_period}_{timestamp}.json"
    filepath = os.path.join(data_dir, filename)
    
    # ä¿å­˜æ–‡ä»¶
    try:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"\n[âœ”] æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        return filepath
    except Exception as e:
        print(f"\n[âœ˜] ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return ""

def build_base_json(data_type: str) -> dict:
    """æ„å»ºJSONè¾“å‡ºçš„åŸºç¡€ç»“æ„"""
    return {
        "crawl_timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        "data_type": data_type, "market_indices": [], "market_sentiment": {},
        "sector_rankings": {}, "long_hu_bang": []
    }

def scrape_midday_data() -> dict:
    """æ‰§è¡Œåˆé—´æ•°æ®æŠ“å–ä»»åŠ¡"""
    print("\n" + "="*30 + "\nğŸš€ å¼€å§‹æ‰§è¡Œ [åˆé—´æ•°æ®] æŠ“å–ä»»åŠ¡...\n" + "="*30)
    output_json = build_base_json("MIDDAY_DATA")
    output_json["market_indices"] = get_market_indices()
    output_json["market_sentiment"] = get_market_sentiment()
    output_json["sector_rankings"] = get_sector_rankings()
    del output_json["long_hu_bang"]
    
    # è‡ªåŠ¨ä¿å­˜ä¸ºJSONæ–‡ä»¶
    _save_to_json_file(output_json, "MIDDAY_DATA")
    
    print("\nâœ… [åˆé—´æ•°æ®] æŠ“å–ä»»åŠ¡å®Œæˆï¼")
    return output_json

def scrape_eod_data() -> dict:
    """æ‰§è¡Œæ¯æ—¥ç›˜åæ•°æ®æŠ“å–ä»»åŠ¡"""
    print("\n" + "="*30 + "\nğŸš€ å¼€å§‹æ‰§è¡Œ [ç›˜åæ•°æ®] æŠ“å–ä»»åŠ¡...\n" + "="*30)
    output_json = build_base_json("EOD_DATA")
    output_json["market_indices"] = get_market_indices()
    output_json["market_sentiment"] = get_market_sentiment()
    output_json["sector_rankings"] = get_sector_rankings()
    output_json["long_hu_bang"] = get_long_hu_bang()
    
    # è‡ªåŠ¨ä¿å­˜ä¸ºJSONæ–‡ä»¶
    _save_to_json_file(output_json, "EOD_DATA")
    
    print("\nâœ… [ç›˜åæ•°æ®] æŠ“å–ä»»åŠ¡å®Œæˆï¼")
    return output_json

# ==============================================================================
# 4. ä¸»ç¨‹åºå…¥å£ (Main Execution Block)
# ==============================================================================

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="ä¸œæ–¹è´¢å¯Œç½‘è´¢ç»æ•°æ®çˆ¬è™« (ç‰ˆæœ¬ 1.2)")
    parser.add_argument('task', type=str, choices=['midday', 'eod'], help="é€‰æ‹©ä»»åŠ¡: 'midday' (åˆé—´) æˆ– 'eod' (ç›˜å)")
    parser.add_argument('--output', type=str, default='', help="æŒ‡å®šè¾“å‡ºJSONæ–‡ä»¶çš„è·¯å¾„ (å¯é€‰)")
    args = parser.parse_args()
    
    result_data = None
    if args.task == 'midday':
        result_data = scrape_midday_data()
    elif args.task == 'eod':
        result_data = scrape_eod_data()
    
    if result_data:
        json_output = json.dumps(result_data, ensure_ascii=False, indent=2)
        if args.output:
            try:
                with open(args.output, 'w', encoding='utf-8') as f:
                    f.write(json_output)
                print(f"\n[âœ”] ç»“æœå·²æˆåŠŸä¿å­˜åˆ°æ–‡ä»¶: {args.output}")
            except IOError as e:
                print(f"\n[âœ˜] ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
        else:
            print("\n--- JSON è¾“å‡ºç»“æœ ---\n" + json_output + "\n---------------------\n")

    # æ–°å¢ï¼šè‡ªåŠ¨ç”Ÿæˆå†…å®¹è§„åˆ’
   
